# Simple Dockerfile - Uses your existing installation
# Much faster build since packages are already installed

FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

# Install Python and system dependencies only
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-venv \
    python3-pip \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.10 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1

# Upgrade pip
RUN python -m pip install --no-cache-dir --upgrade pip

# Copy your WORKING venv or site-packages from host
# Option 1: If you have a venv
# COPY /path/to/your/venv /opt/venv
# ENV PATH="/opt/venv/bin:$PATH"

# Option 2: Install just the packages you need (lightweight)
COPY requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# Install the heavy packages from pre-built wheels (if available)
# Or skip them and install after container is running
RUN pip install --no-cache-dir \
    torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu128 || true

# Copy application code
WORKDIR /app
COPY app/ ./app/
COPY config.yaml .
COPY entrypoint.sh .
RUN chmod +x entrypoint.sh

# Create model directory
RUN mkdir -p /models

ENV CONFIG_PATH=/app/config.yaml
ENV VLLM_MODEL_PATH=/models/Qwen3-VL-8B-Thinking

EXPOSE 5000

HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

ENTRYPOINT ["./entrypoint.sh"]
