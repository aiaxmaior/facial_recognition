# GPU Server Configuration
# Facial Enrollment & Emotion Analysis Service

server:
  host: "0.0.0.0"
  port: 5000
  workers: 1  # Single worker for GPU memory management

# Model configurations
models:
  # Facial embedding model (DeepFace/ArcFace)
  embedding:
    backend: "deepface"
    model_name: "ArcFace"
    detector_backend: "yolov8n"  # must match edge-device detector for embedding compatibility
    embedding_dim: 512
    enforce_detection: true
    align: true

  # Emotion analysis VLM (via vLLM subprocess)
  emotion:
    backend: "vllm"
    llm_base_url: "http://localhost:8000"  # vLLM server running inside container
    model_name: "Qwen/Qwen3-VL-8B-Thinking"
    max_tokens: 256
    temperature: 0.1

# Thumbnail generation
thumbnail:
  size: [128, 128]
  format: "JPEG"
  quality: 85

# Logging
logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
  max_log_entries: 1000
