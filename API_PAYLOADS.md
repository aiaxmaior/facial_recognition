# GPU Server â€“ API Payload Examples

Example request/response payloads for each GPU server function.

---

## 1. Vectorizer (Facial Enrollment)

### Enrollment API Server -> GPU Server

`POST /iot/vectorizer`

5 pose images + employee ID sent by the enrollment API server (which received them from the enrollment modal).

```json
{
  "employee_id": "arjun_joshi_0042",
  "images": [
    { "pose": "front", "data": "/9j/4AAQSkZJRg..." },
    { "pose": "left",  "data": "/9j/4AAQSkZJRg..." },
    { "pose": "right", "data": "/9j/4AAQSkZJRg..." },
    { "pose": "up",    "data": "/9j/4AAQSkZJRg..." },
    { "pose": "down",  "data": "/9j/4AAQSkZJRg..." }
  ],
  "options": {}
}
```

- `employee_id` -- who is being enrolled (required)
- `images` -- 1-5 items, each with optional `pose` and `data` (base64 JPEG)
- `options` -- reserved for future processing flags

### GPU Server -> Enrollment API Server

```json
{
  "employee_id": "arjun_joshi_0042",
  "enrollmentProcessedFile": "DdMkvHbttbxqNRo9yog...",
  "embedding_dim": 512,
  "model": "ArcFace",
  "enrollmentPictureThumbnail": "/9j/4AAQSkZJRg...",
  "image_count": 5,
  "processing_time_ms": 3420
}
```

- `enrollmentProcessedFile` -- base64 Float32Array, 512-dim ArcFace embedding
- `embedding_dim` -- dimensionality of the embedding (512)
- `model` -- which model produced it
- `enrollmentPictureThumbnail` -- base64 128x128 JPEG cropped to face
- `image_count` -- number of images used
- `processing_time_ms` -- server-side wall time

The enrollment API server wraps this into what the **modal** sees:

```json
{
  "success": true,
  "message": "Successfully processed 5 images for arjun_joshi_0042",
  "data": {
    "employee_id": "arjun_joshi_0042",
    "embedding_count": 5,
    "enrollmentPictureThumbnail": "/9j/4AAQSkZJRg...",
    "enrollmentStatus": "captured"
  }
}
```

---

## 2. Emotions (VLM Contextual Analysis)

Emotion recognition runs in real time **on the edge device**. When a threshold is crossed, the edge device sends the emotion data + media to the GPU server. The GPU server feeds everything to the VLM and returns a contextual narrative.

### Edge Device -> GPU Server

`POST /iot/emotions`

- `emotion_recognition.trigger` -- the reading at the moment the threshold was crossed
- `emotion_recognition.timeline` -- array of readings over time (per-frame or per-second)
- `media.type` -- `"images"` now; will become `"video"` when the pipeline evolves to accept .mp4
- `media.frames` -- base64 image frames (current); future: replaced or supplemented by a video field

```json
{
  "event_id": "EV2-1707782400000-jetson007",
  "employee_id": "arjun_joshi_0042",
  "emotion_recognition": {
    "trigger": {
      "frame": 47,
      "timestamp_ms": 3133,
      "happiness": 0.12,
      "sadness": 0.85,
      "anger": 0.45,
      "fear": 0.30,
      "surprise": 0.05,
      "disgust": 0.02,
      "contempt": 0.01,
      "valence": -0.72
    },
    "timeline": [
      {
        "frame": 0,
        "timestamp_ms": 0,
        "happiness": 0.65,
        "sadness": 0.05,
        "anger": 0.02,
        "fear": 0.01,
        "surprise": 0.03,
        "disgust": 0.01,
        "contempt": 0.00,
        "valence": 0.60
      }
    ]
  },
  "media": {
    "type": "images",
    "frames": [
      { "frame": 0, "data": "<base64>" },
      { "frame": 47, "data": "<base64>" }
    ]
  }
}
```

### GPU Server -> Edge Device

```json
{
  "event_id": "EV2-1707782400000-jetson007",
  "gpu_processing_event_id": "gpu-vlm-a3f8c201",
  "employee_id": "arjun_joshi_0042",
  "timestamp": "2026-02-12T18:45:03Z",
  "vlm_analysis": {
    "narrative": "The subject transitions from a calm state to visible distress around frame 47. Sadness and anger spike simultaneously, suggesting a reactive response. The video shows a tense interaction near a workstation -- body language shifts from open to closed posture. Pattern consistent with workplace conflict rather than personal distress.",
    "token_count": 62,
    "model": "Qwen/Qwen3-VL-8B-Thinking"
  },
  "processing_time_ms": 4200
}
```

- `event_id` -- echoed from request
- `gpu_processing_event_id` -- unique ID generated by the GPU server for this processing run
- `employee_id` -- echoed from request
- `timestamp` -- when the GPU server completed processing
- `vlm_analysis.narrative` -- free-text contextual analysis from the VLM (length governed by system prompt / vLLM config)
- `vlm_analysis.token_count` -- actual tokens used in the response
- `vlm_analysis.model` -- which VLM produced the analysis
- `processing_time_ms` -- server-side wall time
